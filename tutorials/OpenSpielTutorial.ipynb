{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "odj1Coq5H080"
      },
      "outputs": [],
      "source": [
        "#@title ##### License { display-mode: \"form\" }\n",
        "# Copyright 2019 DeepMind Technologies Ltd. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOOzDGYAZcW3"
      },
      "source": [
        "# OpenSpiel\n",
        "\n",
        "* This Colab gets you started the basics of OpenSpiel.\n",
        "* OpenSpiel is a framework for reinforcement learning in games. The code is hosted [on github](https://github.com/deepmind/open_spiel/).\n",
        "* There is an accompanying video tutorial that works through this colab. It will be linked here once it is live.\n",
        "* There is also an [OpenSpiel paper](https://arxiv.org/abs/1908.09453) with more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC6kQBzWahEF"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2_Vbijh4FlZ"
      },
      "source": [
        "The following command will install OpenSpiel via pip.\n",
        "\n",
        "Only the required dependencies are installed. You may need other dependencies if you use some of the algorithms. There is a [the complete list of packages and versions](https://github.com/deepmind/open_spiel/blob/master/open_spiel/scripts/python_extra_deps.sh) we install for the CI tests, which can be installed as necessary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lQc12Xrn4CXU"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade open_spiel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUtlXZ8FBnAL"
      },
      "source": [
        "# Part 1. OpenSpiel API Basics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bDXdNLJbsZaD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['2048', 'add_noise', 'amazons', 'backgammon', 'bargaining', 'battleship', 'blackjack', 'blotto', 'breakthrough', 'bridge', 'bridge_uncontested_bidding', 'catch', 'checkers', 'chess', 'cliff_walking', 'clobber', 'coin_game', 'colored_trails', 'connect_four', 'coop_box_pushing', 'coop_to_1p', 'coordinated_mp', 'crazy_eights', 'cursor_go', 'dark_chess', 'dark_hex', 'dark_hex_ir', 'deep_sea', 'dots_and_boxes', 'dou_dizhu', 'efg_game', 'euchre', 'first_sealed_auction', 'gin_rummy', 'go', 'goofspiel', 'havannah', 'hearts', 'hex', 'kriegspiel', 'kuhn_poker', 'laser_tag', 'leduc_poker', 'lewis_signaling', 'liars_dice', 'liars_dice_ir', 'maedn', 'mancala', 'markov_soccer', 'matching_pennies_3p', 'matrix_bos', 'matrix_brps', 'matrix_cd', 'matrix_coordination', 'matrix_mp', 'matrix_pd', 'matrix_rps', 'matrix_rpsw', 'matrix_sh', 'matrix_shapleys_game', 'mfg_crowd_modelling', 'mfg_crowd_modelling_2d', 'mfg_dynamic_routing', 'mfg_garnet', 'misere', 'morpion_solitaire', 'negotiation', 'nfg_game', 'nim', 'nine_mens_morris', 'normal_form_extensive_game', 'oh_hell', 'oshi_zumo', 'othello', 'oware', 'pathfinding', 'pentago', 'phantom_go', 'phantom_ttt', 'phantom_ttt_ir', 'pig', 'quoridor', 'rbc', 'repeated_game', 'restricted_nash_response', 'sheriff', 'skat', 'solitaire', 'start_at', 'stones_and_gems', 'tarok', 'tic_tac_toe', 'tiny_bridge_2p', 'tiny_bridge_4p', 'tiny_hanabi', 'trade_comm', 'turn_based_simultaneous_game', 'ultimate_tic_tac_toe', 'y', 'zerosum']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<module 'pyspiel' from '/home/boulux/projects/open_spiel/build/python/pyspiel.so'>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing pyspiel and showing the list of supported games.\n",
        "import pyspiel\n",
        "print(pyspiel.registered_names())\n",
        "pyspiel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "74glfO8dsmPn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tic_tac_toe()\n"
          ]
        }
      ],
      "source": [
        "# Loading a game (with no/default parameters).\n",
        "game = pyspiel.load_game(\"tic_tac_toe\")\n",
        "print(game)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tthnjDQxuuW1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "1.0\n",
            "-1.0\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "# Some properties of the games.\n",
        "print(game.num_players())\n",
        "print(game.max_utility())\n",
        "print(game.min_utility())\n",
        "print(game.num_distinct_actions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "po2CYySVu-rC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "...\n",
            "...\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "# Creating initial states.\n",
        "state = game.new_initial_state()\n",
        "print(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZxXCiDjXvNMQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "False\n",
            "[0.0, 0.0]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
          ]
        }
      ],
      "source": [
        "# Basic information about states.\n",
        "print(state.current_player())\n",
        "print(state.is_terminal())\n",
        "print(state.returns())\n",
        "print(state.legal_actions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GQypywhgvh6t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".x.\n",
            "...\n",
            "...\n",
            "1\n",
            "oxo\n",
            ".x.\n",
            ".x.\n",
            "True\n",
            "1.0\n",
            "-4\n"
          ]
        }
      ],
      "source": [
        "# Playing the game: applying actions.\n",
        "state = game.new_initial_state()\n",
        "state.apply_action(1)\n",
        "print(state)\n",
        "print(state.current_player())\n",
        "state.apply_action(2)\n",
        "state.apply_action(4)\n",
        "state.apply_action(0)\n",
        "state.apply_action(7)\n",
        "print(state)\n",
        "print(state.is_terminal())\n",
        "print(state.player_return(0))   # win for x (player 0)\n",
        "print(state.current_player())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "fxu3ZTxxvmrW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8bbbbbbbb\n",
            "7bbbbbbbb\n",
            "6........\n",
            "5........\n",
            "4........\n",
            "3........\n",
            "2wwwwwwww\n",
            "1wwwwwwww\n",
            " abcdefgh\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Different game: Breakthrough with default parameters (number of rows and columns are both 8)\n",
        "game = pyspiel.load_game(\"breakthrough\")\n",
        "state = game.new_initial_state()\n",
        "print(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rQV0169-wuLI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6bbbbbb\n",
            "5bbbbbb\n",
            "4......\n",
            "3......\n",
            "2wwwwww\n",
            "1wwwwww\n",
            " abcdef\n",
            "\n",
            "[74, 76, 84, 86, 88, 96, 98, 100, 108, 110, 112, 120, 122, 124, 132, 134]\n",
            "432\n",
            "74 a5a4\n",
            "76 a5b4\n",
            "84 b5a4\n",
            "86 b5b4\n",
            "88 b5c4\n",
            "96 c5b4\n",
            "98 c5c4\n",
            "100 c5d4\n",
            "108 d5c4\n",
            "110 d5d4\n",
            "112 d5e4\n",
            "120 e5d4\n",
            "122 e5e4\n",
            "124 e5f4\n",
            "132 f5e4\n",
            "134 f5f4\n"
          ]
        }
      ],
      "source": [
        "# Parameterized games: loading a 6x6 Breakthrough.\n",
        "game = pyspiel.load_game(\"breakthrough(rows=6,columns=6)\")\n",
        "state = game.new_initial_state()\n",
        "print(state)\n",
        "print(state.legal_actions())\n",
        "print(game.num_distinct_actions())\n",
        "for action in state.legal_actions():\n",
        "  print(f\"{action} {state.action_to_string(action)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeB3zc8AzDlZ"
      },
      "source": [
        "# Part 2. Normal-form Games and Evolutionary Dynamics in OpenSpiel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "u2eRTZr4zm_G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "short_name()\n",
            "Terminal? false\n",
            "Row actions: row0 row1 \n",
            "Col actions: col0 col1 \n",
            "Utility matrix:\n",
            "1,-1 -1,1 \n",
            "-1,1 1,-1 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pyspiel\n",
        "game = pyspiel.create_matrix_game([[1, -1], [-1, 1]], [[-1, 1], [1, -1]])\n",
        "print(game)   # name not provided: uses a default\n",
        "state = game.new_initial_state()\n",
        "print(state)  # action names also not provided; defaults used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "N6E0hG4J0TaI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-2\n",
            "[0, 1]\n",
            "[0, 1]\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# Normal-form games are 1-step simultaneous-move games.\n",
        "print(state.current_player())    # special player id \n",
        "print(state.legal_actions(0))    # query legal actions for each player\n",
        "print(state.legal_actions(1))\n",
        "print(state.is_terminal())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RPfvosEU0pt9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "[1.0, -1.0]\n"
          ]
        }
      ],
      "source": [
        "# Applying a joint action (one action per player)\n",
        "state.apply_actions([0, 0])\n",
        "print(state.is_terminal())\n",
        "print(state.returns())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fq4NRSrz04xe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.08, -0.08,  0.  ])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evolutionary dynamics in Rock, Paper, Scissors\n",
        "from open_spiel.python.egt import dynamics\n",
        "from open_spiel.python.egt.utils import game_payoffs_array\n",
        "import numpy as np\n",
        "\n",
        "game = pyspiel.load_matrix_game(\"matrix_rps\")   # load the Rock, Paper, Scissors matrix game\n",
        "payoff_matrix = game_payoffs_array(game)        # convert any normal-form game to a numpy payoff matrix\n",
        "\n",
        "dyn = dynamics.SinglePopulationDynamics(payoff_matrix, dynamics.replicator)\n",
        "x = np.array([0.2, 0.2, 0.6])                   # population heavily-weighted toward scissors\n",
        "dyn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jPzX2HWK1VvJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.2008 0.1992 0.6   ]\n",
            "[0.20160481 0.19840479 0.5999904 ]\n",
            "[0.20487215 0.19527183 0.59985601]\n"
          ]
        }
      ],
      "source": [
        "# Choose a step size and apply the dynamic\n",
        "alpha = 0.01\n",
        "x += alpha * dyn(x)\n",
        "print(x)\n",
        "x += alpha * dyn(x)\n",
        "print(x)\n",
        "x += alpha * dyn(x)\n",
        "x += alpha * dyn(x)\n",
        "x += alpha * dyn(x)\n",
        "x += alpha * dyn(x)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-i_tT8HzLU1"
      },
      "source": [
        "# Part 3. Chance Nodes and Partially-Observable Games."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bA6hgOQW2iUz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "# Kuhn poker: simplified poker with a 3-card deck (https://en.wikipedia.org/wiki/Kuhn_poker)\n",
        "import pyspiel\n",
        "game = pyspiel.load_game(\"kuhn_poker\")\n",
        "print(game.num_distinct_actions())    # bet and fold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RxVzdLjU2zWM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1\n",
            "True\n",
            "[(0, 0.3333333333333333), (1, 0.3333333333333333), (2, 0.3333333333333333)]\n"
          ]
        }
      ],
      "source": [
        "# Chance nodes.\n",
        "state = game.new_initial_state()\n",
        "print(state.current_player())     # special chance player id\n",
        "print(state.is_chance_node())\n",
        "print(state.chance_outcomes())    # distibution over outcomes as a list of (outcome, probability) pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "avTQrpRA3OOQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "[(1, 0.5), (2, 0.5)]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Applying chance node outcomes: same function as applying actions.\n",
        "state.apply_action(0)              # let's choose the first card (jack)\n",
        "print(state.is_chance_node())      # still at a chance node (player 2's card).\n",
        "print(state.chance_outcomes())     # jack no longer a possible outcome\n",
        "state.apply_action(1)              # second player gets the queen\n",
        "print(state.current_player())      # no longer chance node, time to play!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "UHZ7vU_V4SZm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 1\n",
            "[0, 1]\n",
            "Pass\n",
            "Bet\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# States vs. information states\n",
        "print(state)                              # ground/world state (all information open)\n",
        "print(state.legal_actions())\n",
        "for action in state.legal_actions():\n",
        "  print(state.action_to_string(action))\n",
        "print(state.information_state_string())   # only current player's information!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "RuzH-yOK4xmg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "1p\n",
            "[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "# Take an action (pass / check), second player's turn.\n",
        "# Information state tensor is vector of floats (often bits) representing the information state.\n",
        "state.apply_action(0)\n",
        "print(state.current_player())\n",
        "print(state.information_state_string())   # now contains second player's card and the public action sequence\n",
        "print(state.information_state_tensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tmJbLdme5P8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "Round: 1\n",
            "Player: -1\n",
            "Pot: 2\n",
            "Money (p1 p2 ...): 99 99\n",
            "Cards (public p1 p2 ...): -10000 -10000 -10000 \n",
            "Round 1 sequence: \n",
            "Round 2 sequence: \n",
            "\n",
            "0\n",
            "[Observer: 0][Private: 0][Round 1][Player: 0][Pot: 2][Money: 99 99][Round1: ][Round2: ]\n",
            "[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "# Leduc poker is a larger game (6 cards, two suits), 3 actions: fold, check/call, raise.\n",
        "game = pyspiel.load_game(\"leduc_poker\")\n",
        "print(game.num_distinct_actions())\n",
        "state = game.new_initial_state()\n",
        "print(state)\n",
        "state.apply_action(0)     # first player gets first jack \n",
        "state.apply_action(1)     # second player gets second jack\n",
        "print(state.current_player())\n",
        "print(state.information_state_string())\n",
        "print(state.information_state_tensor())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4MwssaTo58yO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 1]\n",
            "Round: 2\n",
            "Player: -1\n",
            "Pot: 2\n",
            "Money (p1 p2 ...): 99 99\n",
            "Cards (public p1 p2 ...): -10000 0 1 \n",
            "Round 1 sequence: Call, Call\n",
            "Round 2 sequence: \n",
            "\n",
            "[(2, 0.25), (3, 0.25), (4, 0.25), (5, 0.25)]\n",
            "[Observer: 0][Private: 0][Round 2][Player: 0][Pot: 2][Money: 99 99][Public: 2][Round1: 1 1][Round2: ]\n"
          ]
        }
      ],
      "source": [
        "# Let's check until the second round.\n",
        "print(state.legal_actions_mask())    # Helper function for neural networks.\n",
        "state.apply_action(1)     # check\n",
        "state.apply_action(1)     # check\n",
        "print(state)\n",
        "print(state.chance_outcomes())   # public card (4 left in the deck)\n",
        "state.apply_action(2)\n",
        "print(state.information_state_string())   # player 0's turn again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PGnADszzbNP"
      },
      "source": [
        "# Part 4. Basic RL: Self-play Q-Learning in Tic-Tac-Toe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "EnfdHFr7621m"
      },
      "outputs": [],
      "source": [
        "# Let's do independent Q-learning in Tic-Tac-Toe, and play it against random.\n",
        "# RL is based on python/examples/independent_tabular_qlearning.py\n",
        "from open_spiel.python import rl_environment\n",
        "from open_spiel.python import rl_tools\n",
        "from open_spiel.python.algorithms import tabular_qlearner\n",
        "\n",
        "# Create the environment\n",
        "env = rl_environment.Environment(\"tic_tac_toe\")\n",
        "num_players = env.num_players\n",
        "num_actions = env.action_spec()[\"num_actions\"]\n",
        "\n",
        "# Create the agents\n",
        "agents = [\n",
        "    tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions)\n",
        "    for idx in range(num_players)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mDgnvsjZ7vZI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episodes: 0\n",
            "Episodes: 1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episodes: 2000\n",
            "Episodes: 3000\n",
            "Episodes: 4000\n",
            "Episodes: 5000\n",
            "Episodes: 6000\n",
            "Episodes: 7000\n",
            "Episodes: 8000\n",
            "Episodes: 9000\n",
            "Episodes: 10000\n",
            "Episodes: 11000\n",
            "Episodes: 12000\n",
            "Episodes: 13000\n",
            "Episodes: 14000\n",
            "Episodes: 15000\n",
            "Episodes: 16000\n",
            "Episodes: 17000\n",
            "Episodes: 18000\n",
            "Episodes: 19000\n",
            "Episodes: 20000\n",
            "Episodes: 21000\n",
            "Episodes: 22000\n",
            "Episodes: 23000\n",
            "Episodes: 24000\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Train the Q-learning agents in self-play.\n",
        "for cur_episode in range(25000):\n",
        "  if cur_episode % 1000 == 0:\n",
        "    print(f\"Episodes: {cur_episode}\")\n",
        "  time_step = env.reset()\n",
        "  while not time_step.last():\n",
        "    player_id = time_step.observations[\"current_player\"]\n",
        "    agent_output = agents[player_id].step(time_step)\n",
        "    time_step = env.step([agent_output.action])\n",
        "  # Episode is over, step all agents with final info state.\n",
        "  for agent in agents:\n",
        "    agent.step(time_step)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "3GPNio828vyg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "...\n",
            "...\n",
            "...\n",
            "Agent 0 chooses x(1,2)\n",
            "\n",
            "...\n",
            "..x\n",
            "...\n",
            "Agent 1 chooses o(0,2)\n",
            "\n",
            "..o\n",
            "..x\n",
            "...\n",
            "Agent 0 chooses x(1,1)\n",
            "\n",
            "..o\n",
            ".xx\n",
            "...\n",
            "Agent 1 chooses o(2,0)\n",
            "\n",
            "..o\n",
            ".xx\n",
            "o..\n",
            "Agent 0 chooses x(1,0)\n",
            "\n",
            "..o\n",
            "xxx\n",
            "o..\n",
            "[1.0, -1.0]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Q-learning agent against a random agent.\n",
        "from open_spiel.python.algorithms import random_agent\n",
        "eval_agents = [agents[0], random_agent.RandomAgent(1, num_actions, \"Entropy Master 2000\") ]\n",
        "\n",
        "time_step = env.reset()\n",
        "while not time_step.last():\n",
        "  print(\"\")\n",
        "  print(env.get_state)\n",
        "  player_id = time_step.observations[\"current_player\"]\n",
        "  # Note the evaluation flag. A Q-learner will set epsilon=0 here.\n",
        "  agent_output = eval_agents[player_id].step(time_step, is_evaluation=True)\n",
        "  print(f\"Agent {player_id} chooses {env.get_state.action_to_string(agent_output.action)}\")\n",
        "  time_step = env.step([agent_output.action])\n",
        "\n",
        "print(\"\")\n",
        "print(env.get_state)\n",
        "print(time_step.rewards)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "OpenSpielTutorial.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
